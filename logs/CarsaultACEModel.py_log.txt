
===== Running CarsaultACEModel.py at 2025-03-24 01:23:03 =====
[2025-03-24 07:43:43] Using device: cuda
[2025-03-24 07:43:43] Setting up data
[2025-03-24 07:43:43] Setting up network
[2025-03-24 07:43:43] [INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[2025-03-24 07:43:43] [INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[2025-03-24 07:43:43] [INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[2025-03-24 07:43:43] MACs: 950,424.0
[2025-03-24 07:43:43] FLOPs: 1,900,848.0
[2025-03-24 07:43:43] GFLOPs: 0.0019
[2025-03-24 07:43:43] Parameters: 264541.00
[2025-03-24 07:43:43] =================================================================
[2025-03-24 07:43:43] Layer (type:depth-idx)                   Param #
[2025-03-24 07:43:43] =================================================================
[2025-03-24 07:43:43] ChordExtractionCNN                       --
[2025-03-24 07:43:43] ├─GaussianNoise: 1-1                     --
[2025-03-24 07:43:43] ├─BatchNorm2d: 1-2                       2
[2025-03-24 07:43:43] ├─Conv2d: 1-3                            120
[2025-03-24 07:43:43] ├─Dropout2d: 1-4                         --
[2025-03-24 07:43:43] ├─Conv2d: 1-5                            2,616
[2025-03-24 07:43:43] ├─Dropout2d: 1-6                         --
[2025-03-24 07:43:43] ├─Conv2d: 1-7                            7,812
[2025-03-24 07:43:43] ├─Dropout2d: 1-8                         --
[2025-03-24 07:43:43] ├─Linear: 1-9                            248,960
[2025-03-24 07:43:43] ├─Linear: 1-10                           5,031
[2025-03-24 07:43:43] =================================================================
[2025-03-24 07:43:43] Total params: 264,541
[2025-03-24 07:43:43] Trainable params: 264,541
[2025-03-24 07:43:43] Non-trainable params: 0
[2025-03-24 07:43:43] =================================================================
[2025-03-24 07:43:43] Epoch 1, Training Loss: 1.5652072191612025, Validation Loss: 1.3406460931435613
[2025-03-24 07:43:43] Epoch 2, Training Loss: 1.3652934985651386, Validation Loss: 1.2745305201851265
[2025-03-24 07:43:43] Epoch 3, Training Loss: 1.3143212486215987, Validation Loss: 1.244973856108358
[2025-03-24 07:43:43] Epoch 4, Training Loss: 1.2861294912452668, Validation Loss: 1.2254889749993936
[2025-03-24 07:43:43] Epoch 5, Training Loss: 1.2646929271098213, Validation Loss: 1.2100294282979491
[2025-03-24 07:43:43] Epoch 6, Training Loss: 1.2476876195341893, Validation Loss: 1.2040417517062796
[2025-03-24 07:43:43] Epoch 7, Training Loss: 1.234635880267064, Validation Loss: 1.1902202159345352
[2025-03-24 07:43:43] Epoch 8, Training Loss: 1.2235241552653273, Validation Loss: 1.1893071803465631
[2025-03-24 07:43:43] Epoch 9, Training Loss: 1.214073214461254, Validation Loss: 1.180183931245986
[2025-03-24 07:43:43] Epoch 10, Training Loss: 1.2054673606548914, Validation Loss: 1.1731823494273086
[2025-03-24 07:43:43] Epoch 11, Training Loss: 1.1989585784418746, Validation Loss: 1.169851082935832
[2025-03-24 07:43:43] Epoch 12, Training Loss: 1.191770731034588, Validation Loss: 1.1649228296852916
[2025-03-24 07:43:43] Epoch 13, Training Loss: 1.185614364153638, Validation Loss: 1.159510258125026
[2025-03-24 07:43:43] Epoch 14, Training Loss: 1.1797356183839767, Validation Loss: 1.1554541552648996
[2025-03-24 07:43:43] Epoch 15, Training Loss: 1.173325111210111, Validation Loss: 1.1483750136922148
[2025-03-24 07:43:43] Epoch 16, Training Loss: 1.1685578652754784, Validation Loss: 1.1468088206562432
[2025-03-24 07:43:43] Epoch 17, Training Loss: 1.163195974573918, Validation Loss: 1.1427976858722766
[2025-03-24 07:43:43] Epoch 18, Training Loss: 1.1592243751635032, Validation Loss: 1.1399874537696755
[2025-03-24 07:43:43] Epoch 19, Training Loss: 1.1555581950244753, Validation Loss: 1.1357348090305417
[2025-03-24 07:43:43] Epoch 20, Training Loss: 1.150870041575195, Validation Loss: 1.1319198096249665
[2025-03-24 07:43:43] Epoch 21, Training Loss: 1.1448695022032163, Validation Loss: 1.1312551221729124
[2025-03-24 07:43:43] Epoch 22, Training Loss: 1.140887035606299, Validation Loss: 1.1272400072858073
[2025-03-24 07:43:43] Epoch 23, Training Loss: 1.1369599653022797, Validation Loss: 1.125508363842134
[2025-03-24 07:43:43] Epoch 24, Training Loss: 1.1330593162751084, Validation Loss: 1.1221306329401561
[2025-03-24 07:43:43] Epoch 25, Training Loss: 1.1305160045275888, Validation Loss: 1.1202136527199165
[2025-03-24 07:43:43] Epoch 26, Training Loss: 1.1253929670325298, Validation Loss: 1.1181985129021506
[2025-03-24 07:43:43] Epoch 27, Training Loss: 1.1224843038050307, Validation Loss: 1.1191913417753803
[2025-03-24 07:43:43] Epoch 28, Training Loss: 1.119518437343812, Validation Loss: 1.1142092134083252
[2025-03-24 07:43:43] Epoch 29, Training Loss: 1.1168382553045708, Validation Loss: 1.1129460359061782
[2025-03-24 07:43:43] Epoch 30, Training Loss: 1.1118032683373853, Validation Loss: 1.1117607264001095
[2025-03-24 07:43:43] Epoch 31, Training Loss: 1.1086954802887459, Validation Loss: 1.1102623294744145
[2025-03-24 07:43:43] Epoch 32, Training Loss: 1.1063306630229637, Validation Loss: 1.1067801691086472
[2025-03-24 07:43:43] Epoch 33, Training Loss: 1.1036529811315658, Validation Loss: 1.1072016849360184
[2025-03-24 07:43:43] Epoch 34, Training Loss: 1.1003398621575537, Validation Loss: 1.102199444771228
[2025-03-24 07:43:43] Epoch 35, Training Loss: 1.0977542286753834, Validation Loss: 1.1024987432125333
[2025-03-24 07:43:43] Epoch 36, Training Loss: 1.0954601305687386, Validation Loss: 1.103748034553858
[2025-03-24 07:43:43] Epoch 37, Training Loss: 1.0909545857428713, Validation Loss: 1.1002778623882583
[2025-03-24 07:43:43] Epoch 38, Training Loss: 1.0888660918750315, Validation Loss: 1.099627080354251
[2025-03-24 07:43:43] Epoch 39, Training Loss: 1.085782646925955, Validation Loss: 1.0983611215076237
[2025-03-24 07:43:43] Epoch 40, Training Loss: 1.0826576327042736, Validation Loss: 1.098207528936009
[2025-03-24 07:43:43] Epoch 41, Training Loss: 1.0805967660135025, Validation Loss: 1.0967719238340632
[2025-03-24 07:43:43] Epoch 42, Training Loss: 1.0787209272237617, Validation Loss: 1.096147625371029
[2025-03-24 07:43:43] Epoch 43, Training Loss: 1.0759293188061854, Validation Loss: 1.0944596735725383
[2025-03-24 07:43:43] Epoch 44, Training Loss: 1.0719920852282874, Validation Loss: 1.0932011013127207
[2025-03-24 07:43:43] Epoch 45, Training Loss: 1.0702093572149671, Validation Loss: 1.0908462034770752
[2025-03-24 07:43:43] Epoch 46, Training Loss: 1.067516486993942, Validation Loss: 1.090027534450985
[2025-03-24 07:43:43] Epoch 47, Training Loss: 1.065466940934335, Validation Loss: 1.0905646992184281
[2025-03-24 07:43:43] Epoch 48, Training Loss: 1.062462020433948, Validation Loss: 1.0908454847947324
[2025-03-24 07:43:43] Epoch 49, Training Loss: 1.061120143482764, Validation Loss: 1.0895559756824529
[2025-03-24 07:43:43] Epoch 50, Training Loss: 1.0574419730941544, Validation Loss: 1.0918535719770535
[2025-03-24 07:43:43] Epoch 51, Training Loss: 1.0572466676780548, Validation Loss: 1.0873040348502845
[2025-03-24 07:43:43] Epoch 52, Training Loss: 1.0539722915672551, Validation Loss: 1.088953339965088
[2025-03-24 07:43:43] Epoch 53, Training Loss: 1.0506066896413582, Validation Loss: 1.0858637647943439
[2025-03-24 07:43:43] Epoch 54, Training Loss: 1.050634830765894, Validation Loss: 1.0866004986868647
[2025-03-24 07:43:43] Epoch 55, Training Loss: 1.0483901922824355, Validation Loss: 1.0865661669692783
[2025-03-24 07:43:43] Epoch 56, Training Loss: 1.0462246201996215, Validation Loss: 1.087130756766743
[2025-03-24 07:43:43] Epoch 57, Training Loss: 1.0440787604965298, Validation Loss: 1.0846946155865633
[2025-03-24 07:43:43] Epoch 58, Training Loss: 1.043406849034009, Validation Loss: 1.0870784740598942
[2025-03-24 07:43:43] Epoch 59, Training Loss: 1.0410491342205046, Validation Loss: 1.0867811242142638
[2025-03-24 07:43:43] Epoch 60, Training Loss: 1.0375167900806288, Validation Loss: 1.0839679763544796
[2025-03-24 07:43:43] Epoch 61, Training Loss: 1.03730685561277, Validation Loss: 1.0850861541063561
[2025-03-24 07:43:43] Epoch 62, Training Loss: 1.0355550004463128, Validation Loss: 1.0820755815616505
[2025-03-24 07:43:43] Epoch 63, Training Loss: 1.0325891293738598, Validation Loss: 1.0855092149572594
[2025-03-24 07:43:43] Epoch 64, Training Loss: 1.0308455295401093, Validation Loss: 1.0834498987201144
[2025-03-24 07:43:43] Epoch 65, Training Loss: 1.0297181146536831, Validation Loss: 1.0834330145998994
[2025-03-24 07:43:43] Epoch 66, Training Loss: 1.0284973308186727, Validation Loss: 1.0828724278942499
[2025-03-24 07:43:43] Epoch 67, Training Loss: 1.0260928222048653, Validation Loss: 1.0829417705477513
[2025-03-24 07:43:43] Epoch 68, Training Loss: 1.024656490120867, Validation Loss: 1.0814222894888526
[2025-03-24 07:43:43] Epoch 69, Training Loss: 1.02220577726673, Validation Loss: 1.083057982445443
[2025-03-24 07:43:43] Epoch 70, Training Loss: 1.0211203196900178, Validation Loss: 1.0814332552153665
[2025-03-24 07:43:43] Epoch 71, Training Loss: 1.0188234510701994, Validation Loss: 1.08246591423348
[2025-03-24 07:43:43] Epoch 72, Training Loss: 1.0183338083236222, Validation Loss: 1.0802335658740558
[2025-03-24 07:43:43] Epoch 73, Training Loss: 1.0160723004262353, Validation Loss: 1.0847033651545157
[2025-03-24 07:43:43] Epoch 74, Training Loss: 1.0146457325924332, Validation Loss: 1.080342637651467
[2025-03-24 07:43:43] Epoch 75, Training Loss: 1.0136622848322876, Validation Loss: 1.0842439458189272
[2025-03-24 07:43:43] Epoch 76, Training Loss: 1.0116038627989778, Validation Loss: 1.0810410651949354
[2025-03-24 07:43:43] Epoch 77, Training Loss: 1.010801253400166, Validation Loss: 1.0809846863123356
[2025-03-24 07:43:43] Epoch 78, Training Loss: 1.008998119806696, Validation Loss: 1.082648296633339
[2025-03-24 07:43:43] Epoch 79, Training Loss: 1.007988881936733, Validation Loss: 1.0829189705977897
[2025-03-24 07:43:43] Epoch 80, Training Loss: 1.0063131005077859, Validation Loss: 1.078633354552096
[2025-03-24 07:43:43] Epoch 81, Training Loss: 1.00494028060933, Validation Loss: 1.0797116248850163
[2025-03-24 07:43:43] Epoch 82, Training Loss: 1.0054618649528704, Validation Loss: 1.084418169838546
[2025-03-24 07:43:43] Epoch 83, Training Loss: 1.0019009300964388, Validation Loss: 1.081910964708976
[2025-03-24 07:43:43] Epoch 84, Training Loss: 1.0021395452228468, Validation Loss: 1.08041351060441
[2025-03-24 10:59:47] Epoch 85, Training Loss: 1.0005215526808973, Validation Loss: 1.0826963603709296
[2025-03-24 10:59:47] Epoch 86, Training Loss: 0.9993735567378942, Validation Loss: 1.0796818005656765
[2025-03-24 10:59:47] Epoch 87, Training Loss: 0.9983323609407285, Validation Loss: 1.0811568668028326
[2025-03-24 10:59:47] Epoch 88, Training Loss: 0.9960790185567576, Validation Loss: 1.0811714596765527
[2025-03-24 10:59:47] Epoch 89, Training Loss: 0.9945020649946795, Validation Loss: 1.0794438246929132
[2025-03-24 10:59:47] Epoch 90, Training Loss: 0.9925787987770693, Validation Loss: 1.0829494352046023
[2025-03-24 10:59:47] Epoch 91, Training Loss: 0.9928483390531608, Validation Loss: 1.0829538054115013
[2025-03-24 10:59:47] Epoch 92, Training Loss: 0.991378585862006, Validation Loss: 1.0828038702272265
[2025-03-24 10:59:47] Epoch 93, Training Loss: 0.9912445733848071, Validation Loss: 1.0813436805449548
[2025-03-24 10:59:47] Epoch 94, Training Loss: 0.9906125163004914, Validation Loss: 1.0802163813346524
[2025-03-24 10:59:47] Epoch 95, Training Loss: 0.9898324009928244, Validation Loss: 1.0816423072619683
[2025-03-24 10:59:47] Epoch 96, Training Loss: 0.9877837299403303, Validation Loss: 1.080904424360457
[2025-03-24 10:59:47] Epoch 97, Training Loss: 0.9876612507914092, Validation Loss: 1.0803593419958595
[2025-03-24 10:59:47] Epoch 98, Training Loss: 0.9865599149172848, Validation Loss: 1.0803462692513794
[2025-03-24 10:59:47] Epoch 99, Training Loss: 0.9853055232841171, Validation Loss: 1.0809134286086086
[2025-03-24 10:59:47] Epoch 100, Training Loss: 0.9835416212061309, Validation Loss: 1.0834758678455882
[2025-03-24 10:59:47] Epoch 101, Training Loss: 0.981985411498486, Validation Loss: 1.081909053905199
[2025-03-24 10:59:47] Epoch 102, Training Loss: 0.9807598147385718, Validation Loss: 1.083636593101821
[2025-03-24 10:59:47] Epoch 103, Training Loss: 0.9803659296677668, Validation Loss: 1.0800516551205308
[2025-03-24 10:59:47] Epoch 104, Training Loss: 0.9778293564375333, Validation Loss: 1.0838816869737036
[2025-03-24 10:59:47] Epoch 105, Training Loss: 0.9790976078097433, Validation Loss: 1.0828061949822
[2025-03-24 10:59:47] Epoch 106, Training Loss: 0.9777127168948304, Validation Loss: 1.0847020068440123
[2025-03-24 10:59:47] Epoch 107, Training Loss: 0.9782597023552975, Validation Loss: 1.0829464584855584
[2025-03-24 10:59:47] Epoch 108, Training Loss: 0.9775222446407855, Validation Loss: 1.0835177491975119
[2025-03-24 10:59:47] Epoch 109, Training Loss: 0.9748972219095902, Validation Loss: 1.0833269394613116
[2025-03-24 10:59:47] Epoch 110, Training Loss: 0.9735275810388913, Validation Loss: 1.0830024911924683
[2025-03-24 10:59:47] Epoch 111, Training Loss: 0.9744199403596814, Validation Loss: 1.0873103388412053
[2025-03-24 10:59:47] Epoch 112, Training Loss: 0.9710286069895865, Validation Loss: 1.0818086247941454
[2025-03-24 10:59:47] Epoch 113, Training Loss: 0.9711222671334077, Validation Loss: 1.0823111110835908
[2025-03-24 10:59:47] Epoch 114, Training Loss: 0.9702504189247853, Validation Loss: 1.0826468007283774
[2025-03-24 10:59:47] Epoch 115, Training Loss: 0.9706186112364006, Validation Loss: 1.083927685106414
[2025-03-24 10:59:47] Epoch 116, Training Loss: 0.9676470390909827, Validation Loss: 1.0821161604538863
[2025-03-24 10:59:47] Epoch 117, Training Loss: 0.96888812238191, Validation Loss: 1.0833596458834187
[2025-03-24 10:59:47] Epoch 118, Training Loss: 0.9681406906512177, Validation Loss: 1.0833509549332514
[2025-03-24 10:59:47] Epoch 119, Training Loss: 0.9683289068515551, Validation Loss: 1.0838200045081314
[2025-03-24 10:59:47] Epoch 120, Training Loss: 0.9658448193010933, Validation Loss: 1.0832068039959049
[2025-03-24 10:59:47] Epoch 121, Training Loss: 0.9643874373230206, Validation Loss: 1.0833829269319049
[2025-03-24 10:59:47] Epoch 122, Training Loss: 0.9651763469545978, Validation Loss: 1.0865137354272396
[2025-03-24 10:59:47] Epoch 123, Training Loss: 0.9643211865577586, Validation Loss: 1.0859191392852336
[2025-03-24 10:59:47] Epoch 124, Training Loss: 0.9628398583657555, Validation Loss: 1.0854570410268118
[2025-03-24 10:59:47] Epoch 125, Training Loss: 0.9621050864909543, Validation Loss: 1.0832251713401118
[2025-03-24 10:59:47] Epoch 126, Training Loss: 0.9625022469765785, Validation Loss: 1.0842061864107242
[2025-03-24 10:59:47] Epoch 127, Training Loss: 0.9615886511967672, Validation Loss: 1.083463195187622
[2025-03-24 10:59:47] Epoch 128, Training Loss: 0.961852038489824, Validation Loss: 1.0848662230095603
[2025-03-24 10:59:47] Epoch 129, Training Loss: 0.9595831479372261, Validation Loss: 1.0846199588283418
[2025-03-24 10:59:47] Weight Optimization Hit
[2025-03-24 10:59:47] Epoch 130, Training Loss: 0.9513719489354653, Validation Loss: 1.08271833290755
[2025-03-24 10:59:47] Epoch 131, Training Loss: 0.9466251244622501, Validation Loss: 1.0818094689484297
[2025-03-24 10:59:47] Epoch 132, Training Loss: 0.9479628125933041, Validation Loss: 1.0815512532475484
[2025-03-24 10:59:47] Epoch 133, Training Loss: 0.9470463762360185, Validation Loss: 1.086888788409529
[2025-03-24 10:59:47] Epoch 134, Training Loss: 0.9445636642752967, Validation Loss: 1.0816420249993137
[2025-03-24 10:59:47] Epoch 135, Training Loss: 0.9460320119686597, Validation Loss: 1.0832040689008695
[2025-03-24 10:59:47] Epoch 136, Training Loss: 0.9448382079818801, Validation Loss: 1.0840002036015146
[2025-03-24 10:59:47] Epoch 137, Training Loss: 0.944843990198152, Validation Loss: 1.0806596585891313
[2025-03-24 10:59:47] Epoch 138, Training Loss: 0.9433078996016816, Validation Loss: 1.0829233753334306
[2025-03-24 10:59:47] Epoch 139, Training Loss: 0.9427738695664963, Validation Loss: 1.0831571637836939
[2025-03-24 10:59:47] Epoch 140, Training Loss: 0.9425145103436016, Validation Loss: 1.0824125785034568
[2025-03-24 10:59:47] Epoch 141, Training Loss: 0.940774386747212, Validation Loss: 1.085708024125062
[2025-03-24 10:59:47] Epoch 142, Training Loss: 0.942080008010403, Validation Loss: 1.0844415826271385
[2025-03-24 10:59:47] Epoch 143, Training Loss: 0.9416806358224475, Validation Loss: 1.0829490342684096
[2025-03-24 10:59:47] Epoch 144, Training Loss: 0.9409625301622809, Validation Loss: 1.0815339082550564
[2025-03-24 10:59:47] Epoch 145, Training Loss: 0.9396566987680252, Validation Loss: 1.0826511577594173
[2025-03-24 10:59:47] Epoch 146, Training Loss: 0.9399160117786824, Validation Loss: 1.0824364436179195
[2025-03-24 10:59:47] Epoch 147, Training Loss: 0.9397472867496182, Validation Loss: 1.0863906317272536
[2025-03-24 10:59:47] Epoch 148, Training Loss: 0.939388659076682, Validation Loss: 1.0845188330403297
[2025-03-24 10:59:47] Epoch 149, Training Loss: 0.93791944050982, Validation Loss: 1.0860241344424788
[2025-03-24 10:59:47] Epoch 150, Training Loss: 0.9395772706277362, Validation Loss: 1.0845540778487182
[2025-03-24 10:59:47] Epoch 151, Training Loss: 0.9379053413229033, Validation Loss: 1.085025108358957
[2025-03-24 10:59:47] Epoch 152, Training Loss: 0.9371258669388971, Validation Loss: 1.0842204639673378
[2025-03-24 10:59:47] Epoch 153, Training Loss: 0.9382493877567473, Validation Loss: 1.0839193203453503
[2025-03-24 10:59:47] Epoch 154, Training Loss: 0.9375303525310837, Validation Loss: 1.0818565114216994
[2025-03-24 10:59:47] Epoch 155, Training Loss: 0.936148863930968, Validation Loss: 1.0834779944891892
[2025-03-24 10:59:47] Epoch 156, Training Loss: 0.9359511079767694, Validation Loss: 1.0831251430342317
[2025-03-24 10:59:47] Epoch 157, Training Loss: 0.9347089274734169, Validation Loss: 1.0847393037908444
[2025-03-24 10:59:47] Epoch 158, Training Loss: 0.9350007816866136, Validation Loss: 1.0849370139350938
[2025-03-24 10:59:47] Epoch 159, Training Loss: 0.934766644381847, Validation Loss: 1.0839673340219405
[2025-03-24 10:59:47] Epoch 160, Training Loss: 0.9365123584118417, Validation Loss: 1.08688924171253
[2025-03-24 10:59:47] Epoch 161, Training Loss: 0.9344123613729646, Validation Loss: 1.0877995178122257
[2025-03-24 10:59:47] Epoch 162, Training Loss: 0.9332350672296539, Validation Loss: 1.086001666573592
[2025-03-24 10:59:47] Epoch 163, Training Loss: 0.9339510752421939, Validation Loss: 1.08365155809919
[2025-03-24 10:59:47] Epoch 164, Training Loss: 0.9352190961939718, Validation Loss: 1.0846188552324139
[2025-03-24 10:59:47] Epoch 165, Training Loss: 0.9339025433966156, Validation Loss: 1.0852308841361393
[2025-03-24 10:59:47] Epoch 166, Training Loss: 0.935268659807882, Validation Loss: 1.0822722870180996
[2025-03-24 10:59:47] Epoch 167, Training Loss: 0.9346515534923426, Validation Loss: 1.0852682251268189
[2025-03-24 10:59:47] Epoch 168, Training Loss: 0.9321003026469818, Validation Loss: 1.084969880889744
[2025-03-24 10:59:47] Epoch 169, Training Loss: 0.9333452560468545, Validation Loss: 1.0837504090038346
[2025-03-24 10:59:47] Epoch 170, Training Loss: 0.9321772038369913, Validation Loss: 1.0865736462074014
[2025-03-24 10:59:47] Epoch 171, Training Loss: 0.9331852138920719, Validation Loss: 1.0826668029117077
[2025-03-24 10:59:47] Epoch 172, Training Loss: 0.9328569430601573, Validation Loss: 1.0870987553954712
[2025-03-24 10:59:47] Epoch 173, Training Loss: 0.9315356175474434, Validation Loss: 1.0863549351553397
[2025-03-24 10:59:47] Epoch 174, Training Loss: 0.9301205837180799, Validation Loss: 1.086865872025355
[2025-03-24 10:59:47] Epoch 175, Training Loss: 0.9293233840754289, Validation Loss: 1.0858420586968938
[2025-03-24 10:59:47] Epoch 176, Training Loss: 0.9294569875315585, Validation Loss: 1.088404148597508
[2025-03-24 10:59:47] Epoch 177, Training Loss: 0.9309686497858151, Validation Loss: 1.0846712295777718
[2025-03-24 10:59:47] Epoch 178, Training Loss: 0.9310704022930274, Validation Loss: 1.0858404622249849
[2025-03-24 10:59:47] Weight Optimization Hit
[2025-03-24 10:59:47] Epoch 179, Training Loss: 0.9249473410430188, Validation Loss: 1.0843145772587737
[2025-03-24 10:59:47] Epoch 180, Training Loss: 0.9232056504423299, Validation Loss: 1.0854016866642293
[2025-03-24 10:59:47] Epoch 181, Training Loss: 0.9231890825716188, Validation Loss: 1.0829534301647965
[2025-03-24 10:59:47] Epoch 182, Training Loss: 0.9216810925823549, Validation Loss: 1.0841230524049899
[2025-03-24 10:59:47] Epoch 183, Training Loss: 0.9216306214898253, Validation Loss: 1.0842239921107464
[2025-03-24 10:59:47] Epoch 184, Training Loss: 0.9230931490675282, Validation Loss: 1.0851995037889537
[2025-03-24 10:59:47] Epoch 185, Training Loss: 0.9221262073544262, Validation Loss: 1.0874518948049585
[2025-03-24 10:59:47] Epoch 186, Training Loss: 0.9217274658176101, Validation Loss: 1.0869854692406347
[2025-03-24 10:59:47] Epoch 187, Training Loss: 0.9222495974192575, Validation Loss: 1.0863415498675326
[2025-03-24 10:59:47] Epoch 188, Training Loss: 0.921234937109536, Validation Loss: 1.0872818611849586
[2025-03-24 10:59:47] Epoch 189, Training Loss: 0.9199646903537234, Validation Loss: 1.0836309484843643
[2025-03-24 10:59:47] Epoch 190, Training Loss: 0.9211018931354904, Validation Loss: 1.08515103548101
[2025-03-24 10:59:47] Epoch 191, Training Loss: 0.9208607030853795, Validation Loss: 1.0862043567492816
[2025-03-24 10:59:47] Epoch 192, Training Loss: 0.9198628575115269, Validation Loss: 1.0859951219127675
[2025-03-24 10:59:47] Epoch 193, Training Loss: 0.9211985528610275, Validation Loss: 1.0855683036342483
[2025-03-24 10:59:47] Epoch 194, Training Loss: 0.9188756661391714, Validation Loss: 1.0866236397017954
[2025-03-24 10:59:47] Epoch 195, Training Loss: 0.9204529476557685, Validation Loss: 1.087053107760462
[2025-03-24 10:59:47] Epoch 196, Training Loss: 0.9196181368225356, Validation Loss: 1.0859522384425113
[2025-03-24 10:59:47] Epoch 197, Training Loss: 0.9193471558931506, Validation Loss: 1.089079006574967
[2025-03-24 10:59:47] Epoch 198, Training Loss: 0.9193605537885201, Validation Loss: 1.0846034131361728
[2025-03-24 10:59:47] Epoch 199, Training Loss: 0.9211704883026182, Validation Loss: 1.086464183479794
[2025-03-24 10:59:47] Epoch 200, Training Loss: 0.9202025505827388, Validation Loss: 1.090191073470188
[2025-03-24 10:59:47] Epoch 201, Training Loss: 0.9175815042202892, Validation Loss: 1.0892082946703372
[2025-03-24 10:59:47] Epoch 202, Training Loss: 0.9184511081833981, Validation Loss: 1.08694697186692
[2025-03-24 10:59:47] Epoch 203, Training Loss: 0.919590269841593, Validation Loss: 1.08547502120092
[2025-03-24 10:59:47] Epoch 204, Training Loss: 0.9189231110467917, Validation Loss: 1.0865899058007131
[2025-03-24 10:59:47] Epoch 205, Training Loss: 0.9185017333850435, Validation Loss: 1.0866764435049883
[2025-03-24 10:59:47] Epoch 206, Training Loss: 0.9178728629889031, Validation Loss: 1.0862739451908667
[2025-03-24 10:59:47] Epoch 207, Training Loss: 0.9189071822753664, Validation Loss: 1.0874511740139854
[2025-03-24 10:59:47] Epoch 208, Training Loss: 0.9161101942546537, Validation Loss: 1.0849565657695166
[2025-03-24 10:59:47] Epoch 209, Training Loss: 0.9185304811035747, Validation Loss: 1.0859135674949807
[2025-03-24 10:59:47] Epoch 210, Training Loss: 0.9188928036292449, Validation Loss: 1.086667809485572
[2025-03-24 10:59:47] Epoch 211, Training Loss: 0.917710340092619, Validation Loss: 1.085132061285165
[2025-03-24 10:59:47] Epoch 212, Training Loss: 0.9181487131598428, Validation Loss: 1.0883962362900907
[2025-03-24 10:59:47] Epoch 213, Training Loss: 0.9181700494954331, Validation Loss: 1.086173645894197
[2025-03-24 10:59:47] Epoch 214, Training Loss: 0.9171896656574232, Validation Loss: 1.0910364006172248
[2025-03-24 10:59:47] Epoch 215, Training Loss: 0.9175496183803024, Validation Loss: 1.0904206074569953
[2025-03-24 10:59:47] Epoch 216, Training Loss: 0.9165252449953155, Validation Loss: 1.0864881392536891
[2025-03-24 10:59:47] Epoch 217, Training Loss: 0.9161748224377749, Validation Loss: 1.086680440516411
[2025-03-24 10:59:47] Epoch 218, Training Loss: 0.9180245567097486, Validation Loss: 1.0850390455128318
[2025-03-24 10:59:47] Epoch 219, Training Loss: 0.9155270795907126, Validation Loss: 1.0870096800388167
[2025-03-24 10:59:47] Epoch 220, Training Loss: 0.9171581292014286, Validation Loss: 1.090523402924854
[2025-03-24 10:59:47] Epoch 221, Training Loss: 0.9166696477605615, Validation Loss: 1.0853803923983192
[2025-03-24 10:59:47] Epoch 222, Training Loss: 0.9162273045374453, Validation Loss: 1.08669426586585
[2025-03-24 10:59:47] Epoch 223, Training Loss: 0.9154533392453592, Validation Loss: 1.0879518708240594
[2025-03-24 10:59:47] Epoch 224, Training Loss: 0.9147800999577654, Validation Loss: 1.087584602317279
[2025-03-24 10:59:47] Epoch 225, Training Loss: 0.9141341185761503, Validation Loss: 1.089258484491454
[2025-03-24 10:59:47] Epoch 226, Training Loss: 0.9147196596988842, Validation Loss: 1.086442526014457
[2025-03-24 10:59:47] Epoch 227, Training Loss: 0.9149604334723718, Validation Loss: 1.0868639776145415
[2025-03-24 10:59:47] Weight Optimization Hit
[2025-03-24 10:59:47] Epoch 228, Training Loss: 0.911834946764551, Validation Loss: 1.0873611771433578
[2025-03-24 10:59:47] Epoch 229, Training Loss: 0.9129166575356539, Validation Loss: 1.0854731346830393
[2025-03-24 10:59:47] Epoch 230, Training Loss: 0.911898084927769, Validation Loss: 1.0862446966391897
[2025-03-24 10:59:47] Epoch 231, Training Loss: 0.9130204902792823, Validation Loss: 1.0869921262309448
[2025-03-24 10:59:47] Epoch 232, Training Loss: 0.9122963353110213, Validation Loss: 1.087929468711557
[2025-03-24 10:59:47] Epoch 233, Training Loss: 0.9106018530458567, Validation Loss: 1.0856877372351152
[2025-03-24 10:59:47] Epoch 234, Training Loss: 0.9105687880701392, Validation Loss: 1.0867247462766885
[2025-03-24 10:59:47] Epoch 235, Training Loss: 0.9113647950394094, Validation Loss: 1.0863535462975855
[2025-03-24 10:59:47] Epoch 236, Training Loss: 0.9103101337609472, Validation Loss: 1.0874774048515614
[2025-03-24 10:59:47] Epoch 237, Training Loss: 0.9105542195430232, Validation Loss: 1.08662885732127
[2025-03-24 10:59:47] Epoch 238, Training Loss: 0.9098825523071785, Validation Loss: 1.0877158445805308
[2025-03-24 10:59:47] Epoch 239, Training Loss: 0.9112571327329216, Validation Loss: 1.087498975584798
[2025-03-24 10:59:47] Epoch 240, Training Loss: 0.9124760367404369, Validation Loss: 1.0876188497305113
[2025-03-24 10:59:47] Epoch 241, Training Loss: 0.9108611743699038, Validation Loss: 1.0887818176351547
[2025-03-24 10:59:47] Epoch 242, Training Loss: 0.9093498675703306, Validation Loss: 1.0877871559855805
[2025-03-24 10:59:47] Epoch 243, Training Loss: 0.9093703859063768, Validation Loss: 1.0881056233866284
[2025-03-24 10:59:47] Epoch 244, Training Loss: 0.9103525565208136, Validation Loss: 1.0906791828719984
[2025-03-24 10:59:47] Epoch 245, Training Loss: 0.9100277917660958, Validation Loss: 1.0875407391893985
[2025-03-24 10:59:47] Epoch 246, Training Loss: 0.9096907675858698, Validation Loss: 1.0858358034139732
[2025-03-24 10:59:47] Epoch 247, Training Loss: 0.910800797943227, Validation Loss: 1.088429934932421
[2025-03-24 10:59:47] Epoch 248, Training Loss: 0.9125100767941062, Validation Loss: 1.0873987251680104
[2025-03-24 10:59:47] Epoch 249, Training Loss: 0.9079098808098472, Validation Loss: 1.0856014789208022
[2025-03-24 10:59:47] Epoch 250, Training Loss: 0.9091477876526881, Validation Loss: 1.0881907857365565
[2025-03-24 10:59:47] Epoch 251, Training Loss: 0.909513758532477, Validation Loss: 1.086042310023257
[2025-03-24 10:59:47] Epoch 252, Training Loss: 0.9121499293455388, Validation Loss: 1.0898991437834638
[2025-03-24 10:59:47] Epoch 253, Training Loss: 0.908535787213394, Validation Loss: 1.0898645495225818
[2025-03-24 10:59:47] Epoch 254, Training Loss: 0.9090962424581766, Validation Loss: 1.0856027453372443
[2025-03-24 10:59:47] Epoch 255, Training Loss: 0.9104845690192835, Validation Loss: 1.0858625444875711
[2025-03-24 10:59:47] Epoch 256, Training Loss: 0.909313571185549, Validation Loss: 1.0863090899129277
[2025-03-24 10:59:47] Epoch 257, Training Loss: 0.9086743677628757, Validation Loss: 1.0918348155088111
[2025-03-24 10:59:47] Epoch 258, Training Loss: 0.9076010043232255, Validation Loss: 1.0884880831469503
[2025-03-24 10:59:47] Epoch 259, Training Loss: 0.9084975569901915, Validation Loss: 1.0875100780346874
[2025-03-24 10:59:47] Epoch 260, Training Loss: 0.9091152586739096, Validation Loss: 1.0881091700111998
[2025-03-24 10:59:47] Epoch 261, Training Loss: 0.9094161523878531, Validation Loss: 1.0889031476643358
[2025-03-24 10:59:47] Epoch 262, Training Loss: 0.9105123605377733, Validation Loss: 1.0847691810523092
[2025-03-24 10:59:47] Epoch 263, Training Loss: 0.9112177504255051, Validation Loss: 1.0877090735691608
[2025-03-24 10:59:47] Epoch 264, Training Loss: 0.9076750902889025, Validation Loss: 1.0892236181689277
[2025-03-24 10:59:47] Epoch 265, Training Loss: 0.9097289509948899, Validation Loss: 1.0864799612487868
[2025-03-24 10:59:47] Epoch 266, Training Loss: 0.9094074057297993, Validation Loss: 1.0907852754387313
[2025-03-24 10:59:47] Epoch 267, Training Loss: 0.9082744613602481, Validation Loss: 1.0881743829467438
[2025-03-24 10:59:47] Epoch 268, Training Loss: 0.9084451744358477, Validation Loss: 1.0875014749332022
[2025-03-24 10:59:47] Epoch 269, Training Loss: 0.9076947492711036, Validation Loss: 1.0889084944962844
[2025-03-24 10:59:47] Epoch 270, Training Loss: 0.9075367896747868, Validation Loss: 1.0895734427663322
[2025-03-24 10:59:47] Epoch 271, Training Loss: 0.908841952420569, Validation Loss: 1.0880992884832894
[2025-03-24 10:59:47] Epoch 272, Training Loss: 0.90726619579008, Validation Loss: 1.0881824820764805
[2025-03-24 10:59:47] Epoch 273, Training Loss: 0.9090690662400444, Validation Loss: 1.0857426891301376
[2025-03-24 10:59:47] Epoch 274, Training Loss: 0.9094463886259662, Validation Loss: 1.0872058642944955
[2025-03-24 10:59:47] Epoch 275, Training Loss: 0.9090505645447501, Validation Loss: 1.0879407558015182
[2025-03-24 10:59:47] Epoch 276, Training Loss: 0.9089583510520489, Validation Loss: 1.0893451838562047
[2025-03-24 10:59:47] Weight Optimization Hit
[2025-03-24 10:59:47] Epoch 277, Training Loss: 0.9054091622591712, Validation Loss: 1.0881319994054512
[2025-03-24 10:59:47] Epoch 278, Training Loss: 0.9046533178715273, Validation Loss: 1.091512999773905
[2025-03-24 10:59:47] Epoch 279, Training Loss: 0.9045684869464697, Validation Loss: 1.0882405369301176
[2025-03-24 10:59:47] Ending Training Early
[2025-03-24 10:59:47] Accuracy: 0.3177, F1 Score: 0.3057

===== Finished CarsaultACEModel.py at 2025-03-24 10:59:48 (Duration: 9:36:45.104984) =====

