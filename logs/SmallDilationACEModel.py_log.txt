
===== Running SmallDilationACEModel.py at 2025-03-24 10:59:50 =====
[2025-03-25 15:08:19] Using device: cuda
[2025-03-25 15:08:19] Setting up data
[2025-03-25 15:08:19] Setting up network
[2025-03-25 15:08:19] [INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[2025-03-25 15:08:19] [INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[2025-03-25 15:08:19] [INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[2025-03-25 15:08:19] MACs: 871,764,968.0
[2025-03-25 15:08:19] FLOPs: 1,743,529,936.0
[2025-03-25 15:08:19] GFLOPs: 1.7435
[2025-03-25 15:08:19] Parameters: 32260328.00
[2025-03-25 15:08:19] =================================================================
[2025-03-25 15:08:19] Layer (type:depth-idx)                   Param #
[2025-03-25 15:08:19] =================================================================
[2025-03-25 15:08:19] SmallDilationModel                       --
[2025-03-25 15:08:19] ├─Part1BatchNorm: 1-1                    --
[2025-03-25 15:08:19] │    └─GaussianNoise: 2-1                --
[2025-03-25 15:08:19] │    └─Conv2d: 2-2                       30
[2025-03-25 15:08:19] │    └─BatchNorm2d: 2-3                  6
[2025-03-25 15:08:19] │    └─Conv2d: 2-4                       168
[2025-03-25 15:08:19] │    └─BatchNorm2d: 2-5                  12
[2025-03-25 15:08:19] │    └─Conv2d: 2-6                       495
[2025-03-25 15:08:19] │    └─BatchNorm2d: 2-7                  18
[2025-03-25 15:08:19] │    └─Dropout2d: 2-8                    --
[2025-03-25 15:08:19] │    └─Conv2d: 2-9                       984
[2025-03-25 15:08:19] │    └─BatchNorm2d: 2-10                 24
[2025-03-25 15:08:19] │    └─Conv2d: 2-11                      2,616
[2025-03-25 15:08:19] │    └─BatchNorm2d: 2-12                 48
[2025-03-25 15:08:19] │    └─Conv2d: 2-13                      10,416
[2025-03-25 15:08:19] │    └─Dropout2d: 2-14                   --
[2025-03-25 15:08:19] │    └─BatchNorm2d: 2-15                 96
[2025-03-25 15:08:19] │    └─Conv2d: 2-16                      55,424
[2025-03-25 15:08:19] │    └─BatchNorm2d: 2-17                 256
[2025-03-25 15:08:19] ├─Part2Dilation: 1-2                     --
[2025-03-25 15:08:19] │    └─Conv2d: 2-18                      295,168
[2025-03-25 15:08:19] │    └─Conv2d: 2-19                      1,180,160
[2025-03-25 15:08:19] │    └─Conv2d: 2-20                      2,359,808
[2025-03-25 15:08:19] ├─Part3AttentionBlock: 1-3               --
[2025-03-25 15:08:19] │    └─SqueezeExcitationBlock: 2-21      --
[2025-03-25 15:08:19] │    │    └─Linear: 3-1                  16,384
[2025-03-25 15:08:19] │    │    └─Linear: 3-2                  16,384
[2025-03-25 15:08:19] │    │    └─Sigmoid: 3-3                 --
[2025-03-25 15:08:19] │    └─Linear: 2-22                      28,311,808
[2025-03-25 15:08:19] │    └─Linear: 2-23                      10,023
[2025-03-25 15:08:19] =================================================================
[2025-03-25 15:08:19] Total params: 32,260,328
[2025-03-25 15:08:19] Trainable params: 32,260,328
[2025-03-25 15:08:19] Non-trainable params: 0
[2025-03-25 15:08:19] =================================================================
[2025-03-25 15:08:19] Epoch 1, Training Loss: 1.3041380772203282, Validation Loss: 1.185974596192634
[2025-03-25 15:08:19] Epoch 2, Training Loss: 1.145979087902382, Validation Loss: 1.1138522842175926
[2025-03-25 15:08:19] Epoch 3, Training Loss: 1.0514241637917026, Validation Loss: 1.0660930632847019
[2025-03-25 15:08:19] Epoch 4, Training Loss: 0.937472711878186, Validation Loss: 1.0476452105141
[2025-03-25 15:08:19] Epoch 5, Training Loss: 0.7885742677885565, Validation Loss: 1.0492276880384863
[2025-03-25 15:08:19] Epoch 6, Training Loss: 0.6099073220129347, Validation Loss: 1.0945808570999032
[2025-03-25 15:08:19] Epoch 7, Training Loss: 0.43593548986619274, Validation Loss: 1.239034912159469
[2025-03-25 15:08:19] Epoch 8, Training Loss: 0.29488451546586775, Validation Loss: 1.4189208247474667
[2025-03-25 15:08:19] Epoch 9, Training Loss: 0.20363488917093864, Validation Loss: 1.61998174601103
[2025-03-25 15:08:19] Epoch 10, Training Loss: 0.14996601615118382, Validation Loss: 1.7838252359964357
[2025-03-25 15:08:19] Epoch 11, Training Loss: 0.11799416146496934, Validation Loss: 2.169804673998067
[2025-03-25 15:08:19] Epoch 12, Training Loss: 0.09917912625807303, Validation Loss: 2.1965792248764355
[2025-03-25 15:08:19] Epoch 13, Training Loss: 0.08718765337714397, Validation Loss: 2.1586575011468967
[2025-03-25 15:08:19] Epoch 14, Training Loss: 0.07686690865484479, Validation Loss: 2.1448351699186112
[2025-03-25 15:08:19] Epoch 15, Training Loss: 0.07149426778821824, Validation Loss: 2.313763451086388
[2025-03-25 15:08:19] Epoch 16, Training Loss: 0.066005606743778, Validation Loss: 2.7967452715512966
[2025-03-25 15:08:19] Epoch 17, Training Loss: 0.06145801951243262, Validation Loss: 2.7987412073363016
[2025-03-25 15:08:19] Epoch 18, Training Loss: 0.058280551991767675, Validation Loss: 2.5673381297470246
[2025-03-25 15:08:19] Epoch 19, Training Loss: 0.05554080162915176, Validation Loss: 2.8349569411256184
[2025-03-25 15:08:19] Epoch 20, Training Loss: 0.05261747906190255, Validation Loss: 2.7400131526879696
[2025-03-25 15:08:19] Epoch 21, Training Loss: 0.051078243464106686, Validation Loss: 2.5586705445336215
[2025-03-25 15:08:19] Epoch 22, Training Loss: 0.05062219988660526, Validation Loss: 3.381084559339684
[2025-03-25 15:08:19] Epoch 23, Training Loss: 0.04856442317623298, Validation Loss: 2.8914096976938217
[2025-03-25 15:08:19] Epoch 24, Training Loss: 0.04685046454582268, Validation Loss: 3.1419543715555904
[2025-03-25 15:08:19] Epoch 25, Training Loss: 0.0472944790297909, Validation Loss: 2.3944133174539233
[2025-03-25 15:08:19] Epoch 26, Training Loss: 0.046109580211295145, Validation Loss: 2.4821573628817486
[2025-03-25 15:08:19] Epoch 27, Training Loss: 0.045872792829854674, Validation Loss: 2.9879821945110563
[2025-03-25 15:08:19] Epoch 28, Training Loss: 0.04572536370464704, Validation Loss: 3.24535549870344
[2025-03-25 15:08:19] Epoch 29, Training Loss: 0.04515958285282111, Validation Loss: 3.2079707101729436
[2025-03-25 15:08:19] Epoch 30, Training Loss: 0.04535201960908029, Validation Loss: 2.753017698931054
[2025-03-25 15:08:19] Epoch 31, Training Loss: 0.044357578555847106, Validation Loss: 3.128970322860694
[2025-03-25 15:08:19] Epoch 32, Training Loss: 0.04528876011138644, Validation Loss: 3.094892827336245
[2025-03-25 15:08:19] Epoch 33, Training Loss: 0.04539863994158682, Validation Loss: 3.251775729054514
[2025-03-25 15:08:19] Epoch 34, Training Loss: 0.04472737501029623, Validation Loss: 2.893143591905763
[2025-03-25 15:08:19] Epoch 35, Training Loss: 0.04580407305340051, Validation Loss: 3.46695338018648
[2025-03-25 15:08:19] Epoch 36, Training Loss: 0.043965117787332406, Validation Loss: 3.087156223586361
[2025-03-25 15:08:19] Epoch 37, Training Loss: 0.04530473052433262, Validation Loss: 2.696609002214497
[2025-03-25 15:08:19] Epoch 38, Training Loss: 0.04472730668874205, Validation Loss: 2.820752653331773
[2025-03-25 15:08:19] Epoch 39, Training Loss: 0.04656329618256776, Validation Loss: 3.1648692075333855
[2025-03-25 15:08:19] Epoch 40, Training Loss: 0.04533186936095556, Validation Loss: 3.0114433023804668
[2025-03-25 15:08:19] Epoch 41, Training Loss: 0.0446963230369928, Validation Loss: 2.830788445866525
[2025-03-25 15:08:19] Epoch 42, Training Loss: 0.04553841395032432, Validation Loss: 2.7764880225859097
[2025-03-25 15:08:19] Epoch 43, Training Loss: 0.045647359121253735, Validation Loss: 2.6993207123317204
[2025-03-25 15:08:19] Epoch 44, Training Loss: 0.04656719727794964, Validation Loss: 3.0921294342711465
[2025-03-25 15:08:19] Epoch 45, Training Loss: 0.046010641342216885, Validation Loss: 3.1014775516055875
[2025-03-25 15:08:19] Epoch 46, Training Loss: 0.04572720160404333, Validation Loss: 2.528201260925221
[2025-03-25 15:08:19] Epoch 47, Training Loss: 0.04723231527529875, Validation Loss: 2.844183527871856
[2025-03-25 15:08:19] Epoch 48, Training Loss: 0.0465286378238839, Validation Loss: 2.9292677126233184
[2025-03-25 15:08:19] Epoch 49, Training Loss: 0.04661040630764651, Validation Loss: 2.8140801004923057
[2025-03-25 15:08:19] Epoch 50, Training Loss: 0.046880496319922665, Validation Loss: 3.081829323852677
[2025-03-25 15:08:19] Epoch 51, Training Loss: 0.046466088255952054, Validation Loss: 3.240336560916286
[2025-03-25 15:08:19] Epoch 52, Training Loss: 0.04687626877626383, Validation Loss: 2.8119235528836857
[2025-03-25 15:08:19] Epoch 53, Training Loss: 0.04704910452170728, Validation Loss: 2.4572643183688285
[2025-03-25 15:08:19] Weight Optimization Hit
[2025-03-25 15:08:19] Epoch 54, Training Loss: 0.018376767403852308, Validation Loss: 2.9020077547580505
[2025-03-25 15:08:19] Epoch 55, Training Loss: 0.017328687393688414, Validation Loss: 3.661201980707272
[2025-03-25 15:08:19] Epoch 56, Training Loss: 0.019072244432857027, Validation Loss: 3.5387046175345453
[2025-03-25 15:08:19] Epoch 57, Training Loss: 0.019490295853413223, Validation Loss: 3.7171023098860423
[2025-03-25 15:08:19] Epoch 58, Training Loss: 0.02049654879065644, Validation Loss: 3.3402283109057813
[2025-03-25 15:08:19] Epoch 59, Training Loss: 0.021413396532247712, Validation Loss: 3.372556258945802
[2025-03-25 15:08:19] Epoch 60, Training Loss: 0.02265794044122227, Validation Loss: 3.110057000450925
[2025-03-25 15:08:19] Epoch 61, Training Loss: 0.02306717744539527, Validation Loss: 4.206622933276587
[2025-03-25 15:08:19] Epoch 62, Training Loss: 0.024741965696548594, Validation Loss: 3.662597170141526
[2025-03-25 15:08:19] Epoch 63, Training Loss: 0.02552900833376813, Validation Loss: 3.8794452909101893
[2025-03-25 15:08:19] Epoch 64, Training Loss: 0.026594405609742026, Validation Loss: 3.1560863671879824
[2025-03-25 15:08:19] Epoch 65, Training Loss: 0.0281337190262307, Validation Loss: 3.3780705214716504
[2025-03-25 15:08:19] Epoch 66, Training Loss: 0.02834150335717067, Validation Loss: 3.7843253016296905
[2025-03-25 15:08:19] Epoch 67, Training Loss: 0.03060862592895534, Validation Loss: 3.554398228961382
[2025-03-25 15:08:19] Epoch 68, Training Loss: 0.03029049128069604, Validation Loss: 2.5198192526181176
[2025-03-25 15:08:19] Epoch 69, Training Loss: 0.03312461584916881, Validation Loss: 3.401968384924382
[2025-03-25 15:08:19] Epoch 70, Training Loss: 0.03254944099259282, Validation Loss: 3.454638753353837
[2025-03-25 21:35:04] Epoch 71, Training Loss: 0.03511951485746116, Validation Loss: 2.9577808482788974
[2025-03-25 21:35:04] Epoch 72, Training Loss: 0.035301020495633675, Validation Loss: 3.465140873192477
[2025-03-25 21:35:04] Epoch 73, Training Loss: 0.035806398275574275, Validation Loss: 3.5162891719491
[2025-03-25 21:35:04] Epoch 74, Training Loss: 0.036562244708652776, Validation Loss: 2.719522865766714
[2025-03-25 21:35:04] Epoch 75, Training Loss: 0.036892896939908944, Validation Loss: 3.223821105992272
[2025-03-25 21:35:04] Epoch 76, Training Loss: 0.03920677171259886, Validation Loss: 3.4990407594417174
[2025-03-25 21:35:04] Epoch 77, Training Loss: 0.03876059116500321, Validation Loss: 3.008430280310196
[2025-03-25 21:35:04] Epoch 78, Training Loss: 0.03954848100454116, Validation Loss: 3.4766404764625656
[2025-03-25 21:35:04] Epoch 79, Training Loss: 0.039327258943842716, Validation Loss: 3.41217686673171
[2025-03-25 21:35:04] Epoch 80, Training Loss: 0.041907329055586036, Validation Loss: 3.357153613885602
[2025-03-25 21:35:04] Epoch 81, Training Loss: 0.041733047448918405, Validation Loss: 3.948008543636011
[2025-03-25 21:35:04] Epoch 82, Training Loss: 0.04095638169440142, Validation Loss: 2.8639225995628435
[2025-03-25 21:35:04] Epoch 83, Training Loss: 0.04188330182702316, Validation Loss: 3.183594805672212
[2025-03-25 21:35:04] Epoch 84, Training Loss: 0.04217451568849026, Validation Loss: 3.347493825154787
[2025-03-25 21:35:04] Epoch 85, Training Loss: 0.04318825177356371, Validation Loss: 2.9160233695094564
[2025-03-25 21:35:04] Epoch 86, Training Loss: 0.04288027619353327, Validation Loss: 3.6311699074025396
[2025-03-25 21:35:04] Epoch 87, Training Loss: 0.04144939569718444, Validation Loss: 2.9931455515611742
[2025-03-25 21:35:04] Epoch 88, Training Loss: 0.042760072200153494, Validation Loss: 2.7114401889342234
[2025-03-25 21:35:04] Epoch 89, Training Loss: 0.0410082421688832, Validation Loss: 3.138032470178256
[2025-03-25 21:35:04] Epoch 90, Training Loss: 0.04376798475443362, Validation Loss: 2.849245593279866
[2025-03-25 21:35:04] Epoch 91, Training Loss: 0.042801251237014296, Validation Loss: 2.892240564860947
[2025-03-25 21:35:04] Epoch 92, Training Loss: 0.04441682105368111, Validation Loss: 2.7983117504513286
[2025-03-25 21:35:04] Epoch 93, Training Loss: 0.04518553070179191, Validation Loss: 3.0734205500997995
[2025-03-25 21:35:04] Epoch 94, Training Loss: 0.04371704710202328, Validation Loss: 2.7549372109311436
[2025-03-25 21:35:04] Epoch 95, Training Loss: 0.04564112813187484, Validation Loss: 3.2809063705894417
[2025-03-25 21:35:04] Epoch 96, Training Loss: 0.04379619288265127, Validation Loss: 2.3796427611943884
[2025-03-25 21:35:04] Epoch 97, Training Loss: 0.04335607760592023, Validation Loss: 3.6624205442440685
[2025-03-25 21:35:04] Epoch 98, Training Loss: 0.04468605611974059, Validation Loss: 3.3998860030013986
[2025-03-25 21:35:04] Epoch 99, Training Loss: 0.044484221424881995, Validation Loss: 3.210505260041287
[2025-03-25 21:35:04] Epoch 100, Training Loss: 0.04492443167486076, Validation Loss: 3.6738767555493315
[2025-03-25 21:35:04] Epoch 101, Training Loss: 0.044461506758482656, Validation Loss: 3.396791394642652
[2025-03-25 21:35:04] Epoch 102, Training Loss: 0.043348997141148475, Validation Loss: 2.899766435105328
[2025-03-25 21:35:04] Weight Optimization Hit
[2025-03-25 21:35:04] Epoch 103, Training Loss: 0.01667710331291006, Validation Loss: 3.1078629173598498
[2025-03-25 21:35:04] Epoch 104, Training Loss: 0.017189335301063584, Validation Loss: 3.182663256767717
[2025-03-25 21:35:04] Epoch 105, Training Loss: 0.01808043158661512, Validation Loss: 3.6008199039154314
[2025-03-25 21:35:04] Epoch 106, Training Loss: 0.01770534994239902, Validation Loss: 3.060998709089477
[2025-03-25 21:35:04] Epoch 107, Training Loss: 0.02052249077333087, Validation Loss: 2.9331013740033054
[2025-03-25 21:35:04] Epoch 108, Training Loss: 0.019928606883595545, Validation Loss: 2.5231590567153903
[2025-03-25 21:35:04] Epoch 109, Training Loss: 0.020503934574334387, Validation Loss: 2.8435261166906427
[2025-03-25 21:35:04] Epoch 110, Training Loss: 0.02126402269949411, Validation Loss: 3.215077194237729
[2025-03-25 21:35:04] Epoch 111, Training Loss: 0.02217141265133795, Validation Loss: 3.3444744000835547
[2025-03-25 21:35:04] Epoch 112, Training Loss: 0.022184468319439182, Validation Loss: 3.139283988250268
[2025-03-25 21:35:04] Epoch 113, Training Loss: 0.024433324142763245, Validation Loss: 2.8851831853496455
[2025-03-25 21:35:04] Epoch 114, Training Loss: 0.02822905881402373, Validation Loss: 2.899762636901611
[2025-03-25 21:35:04] Epoch 115, Training Loss: 0.027455212098497342, Validation Loss: 2.888958971037295
[2025-03-25 21:35:04] Epoch 116, Training Loss: 0.025621999478136114, Validation Loss: 3.211079947883766
[2025-03-25 21:35:04] Epoch 117, Training Loss: 0.027396014194217264, Validation Loss: 3.3860378491963536
[2025-03-25 21:35:04] Epoch 118, Training Loss: 0.027411143039279818, Validation Loss: 3.0459254443862505
[2025-03-25 21:35:04] Epoch 119, Training Loss: 0.02882967937867173, Validation Loss: 2.98456269549145
[2025-03-25 21:35:04] Epoch 120, Training Loss: 0.029497876189426026, Validation Loss: 3.6263987523736123
[2025-03-25 21:35:04] Epoch 121, Training Loss: 0.02959301991261696, Validation Loss: 4.372784543627364
[2025-03-25 21:35:04] Epoch 122, Training Loss: 0.030041331366661553, Validation Loss: 2.456392259137201
[2025-03-25 21:35:04] Epoch 123, Training Loss: 0.030303036345856255, Validation Loss: 3.0679098601891224
[2025-03-25 21:35:04] Epoch 124, Training Loss: 0.031457846236617314, Validation Loss: 3.3781653381189134
[2025-03-25 21:35:04] Epoch 125, Training Loss: 0.03214603769192572, Validation Loss: 4.368705928011661
[2025-03-25 21:35:04] Epoch 126, Training Loss: 0.03292464405612157, Validation Loss: 4.493112907000183
[2025-03-25 21:35:04] Epoch 127, Training Loss: 0.034092877134955235, Validation Loss: 3.427864398235008
[2025-03-25 21:35:04] Epoch 128, Training Loss: 0.03327647824702065, Validation Loss: 3.103857060948048
[2025-03-25 21:35:04] Epoch 129, Training Loss: 0.03466113546653127, Validation Loss: 3.243442699592984
[2025-03-25 21:35:04] Epoch 130, Training Loss: 0.033983084172723194, Validation Loss: 3.1218050461417186
[2025-03-25 21:35:04] Epoch 131, Training Loss: 0.03271470774168073, Validation Loss: 3.6356148486890594
[2025-03-25 21:35:04] Epoch 132, Training Loss: 0.035301650620655003, Validation Loss: 3.134944994740157
[2025-03-25 21:35:04] Epoch 133, Training Loss: 0.034401272801081045, Validation Loss: 3.158986547538438
[2025-03-25 21:35:04] Epoch 134, Training Loss: 0.03442514982653643, Validation Loss: 3.552831499788571
[2025-03-25 21:35:04] Epoch 135, Training Loss: 0.03463467485350596, Validation Loss: 3.4482370027059632
[2025-03-25 21:35:04] Epoch 136, Training Loss: 0.035156404853519764, Validation Loss: 2.9023102853364757
[2025-03-25 21:35:04] Epoch 137, Training Loss: 0.034729965670360026, Validation Loss: 3.130915567098835
[2025-03-25 21:35:04] Epoch 138, Training Loss: 0.03604595466256867, Validation Loss: 3.3494934418898716
[2025-03-25 21:35:04] Epoch 139, Training Loss: 0.03606678468992549, Validation Loss: 3.30542259148969
[2025-03-25 21:35:04] Epoch 140, Training Loss: 0.03611334354086759, Validation Loss: 3.092444074978975
[2025-03-25 21:35:04] Epoch 141, Training Loss: 0.03768243471289953, Validation Loss: 2.8034070199987053
[2025-03-25 21:35:04] Epoch 142, Training Loss: 0.03612097667115566, Validation Loss: 3.1894006544304934
[2025-03-25 21:35:04] Epoch 143, Training Loss: 0.03713860567686, Validation Loss: 2.292198218380592
[2025-03-25 21:35:04] Epoch 144, Training Loss: 0.03661672903266356, Validation Loss: 2.615584576888636
[2025-03-25 21:35:04] Epoch 145, Training Loss: 0.03701027783768268, Validation Loss: 3.468063357783696
[2025-03-25 21:35:04] Epoch 146, Training Loss: 0.0369377689183473, Validation Loss: 3.4097877961001863
[2025-03-25 21:35:04] Epoch 147, Training Loss: 0.035467965760485255, Validation Loss: 3.718176800659723
[2025-03-25 21:35:04] Epoch 148, Training Loss: 0.038424867446606004, Validation Loss: 3.6287158016030427
[2025-03-25 21:35:04] Epoch 149, Training Loss: 0.03794244830563685, Validation Loss: 3.358538390443746
[2025-03-25 21:35:04] Epoch 150, Training Loss: 0.03816565525647657, Validation Loss: 2.9072832735415868
[2025-03-25 21:35:04] Epoch 151, Training Loss: 0.039061063083916096, Validation Loss: 3.1745568174057808
[2025-03-25 21:35:04] Weight Optimization Hit
[2025-03-25 21:35:04] Epoch 152, Training Loss: 0.014531490234882009, Validation Loss: 2.390093289347722
[2025-03-25 21:35:04] Epoch 153, Training Loss: 0.01502352923405787, Validation Loss: 2.9049881117031853
[2025-03-25 21:35:04] Epoch 154, Training Loss: 0.015119050922274344, Validation Loss: 3.1932952224465248
[2025-03-25 21:35:04] Epoch 155, Training Loss: 0.019491724729927672, Validation Loss: 3.249906467128315
[2025-03-25 21:35:04] Epoch 156, Training Loss: 0.01713078993787477, Validation Loss: 3.1619580911343723
[2025-03-25 21:35:04] Epoch 157, Training Loss: 0.0175360083009078, Validation Loss: 2.5048979539275718
[2025-03-25 21:35:04] Epoch 158, Training Loss: 0.020281739763831387, Validation Loss: 3.305890991821437
[2025-03-25 21:35:04] Epoch 159, Training Loss: 0.018854144148141183, Validation Loss: 2.6624111867089475
[2025-03-25 21:35:04] Epoch 160, Training Loss: 0.01805740142947421, Validation Loss: 2.7261403762618945
[2025-03-25 21:35:04] Epoch 161, Training Loss: 0.019317917791018595, Validation Loss: 3.047350858205012
[2025-03-25 21:35:04] Epoch 162, Training Loss: 0.019206155200259683, Validation Loss: 2.95860782896883
[2025-03-25 21:35:04] Epoch 163, Training Loss: 0.019148800046398934, Validation Loss: 3.450216757324372
[2025-03-25 21:35:04] Epoch 164, Training Loss: 0.025049248743754395, Validation Loss: 2.5841330771835223
[2025-03-25 21:35:04] Epoch 165, Training Loss: 0.019611549564296036, Validation Loss: 3.1154724521246426
[2025-03-25 21:35:04] Epoch 166, Training Loss: 0.02041395686813078, Validation Loss: 3.6624190879863336
[2025-03-25 21:35:04] Epoch 167, Training Loss: 0.020624892855355178, Validation Loss: 2.864753784778248
[2025-03-25 21:35:04] Epoch 168, Training Loss: 0.020340616961512407, Validation Loss: 3.2986796205460207
[2025-03-25 21:35:04] Epoch 169, Training Loss: 0.02057548128387265, Validation Loss: 2.414737664763899
[2025-03-25 21:35:04] Epoch 170, Training Loss: 0.020843942580702834, Validation Loss: 2.716284015489681
[2025-03-25 21:35:04] Epoch 171, Training Loss: 0.022200184311274778, Validation Loss: 2.6667614340347434
[2025-03-25 21:35:04] Epoch 172, Training Loss: 0.020802636301373963, Validation Loss: 2.5782126112381145
[2025-03-25 21:35:04] Epoch 173, Training Loss: 0.021159017329072397, Validation Loss: 2.789164137272695
[2025-03-25 21:35:04] Epoch 174, Training Loss: 0.022726346087301105, Validation Loss: 2.9924832818477367
[2025-03-25 21:35:04] Epoch 175, Training Loss: 0.022186772872376317, Validation Loss: 3.0786276063067
[2025-03-25 21:35:04] Epoch 176, Training Loss: 0.023704638445219018, Validation Loss: 2.940442153908737
[2025-03-25 21:35:04] Epoch 177, Training Loss: 0.023426790497898205, Validation Loss: 2.783122278591103
[2025-03-25 21:35:04] Epoch 178, Training Loss: 0.026182730327900465, Validation Loss: 3.0401010504660486
[2025-03-25 21:35:04] Epoch 179, Training Loss: 0.0224960458526069, Validation Loss: 2.425916031633741
[2025-03-25 21:35:04] Epoch 180, Training Loss: 0.025441131039625517, Validation Loss: 2.4890807892857922
[2025-03-25 21:35:04] Epoch 181, Training Loss: 0.02423357249750322, Validation Loss: 2.6959444334666727
[2025-03-25 21:35:04] Epoch 182, Training Loss: 0.024073463829859025, Validation Loss: 2.354894532985739
[2025-03-25 21:35:04] Epoch 183, Training Loss: 0.024596013338130024, Validation Loss: 2.791289798434784
[2025-03-25 21:35:04] Epoch 184, Training Loss: 0.025165074079616306, Validation Loss: 2.4804919498478144
[2025-03-25 21:35:04] Epoch 185, Training Loss: 0.026035039201648014, Validation Loss: 2.9266253563529445
[2025-03-25 21:35:04] Epoch 186, Training Loss: 0.02510673002913214, Validation Loss: 2.9583746127910326
[2025-03-25 21:35:04] Epoch 187, Training Loss: 0.026118731844763154, Validation Loss: 3.0373705945767315
[2025-03-25 21:35:04] Epoch 188, Training Loss: 0.026080308498095284, Validation Loss: 2.909069844301039
[2025-03-25 21:35:04] Epoch 189, Training Loss: 0.02413696467047948, Validation Loss: 3.6466122843168947
[2025-03-25 21:35:04] Epoch 190, Training Loss: 0.02533677259957191, Validation Loss: 3.074445849963577
[2025-03-25 21:35:04] Epoch 191, Training Loss: 0.02507189660557953, Validation Loss: 3.6462988580928246
[2025-03-25 21:35:04] Epoch 192, Training Loss: 0.025710905182731832, Validation Loss: 3.97691198690863
[2025-03-25 21:35:04] Epoch 193, Training Loss: 0.02517428852921258, Validation Loss: 2.9506382897866277
[2025-03-25 21:35:04] Epoch 194, Training Loss: 0.026082017117886658, Validation Loss: 2.6754740451752523
[2025-03-25 21:35:04] Epoch 195, Training Loss: 0.025205424652789146, Validation Loss: 3.184390906374719
[2025-03-25 21:35:04] Epoch 196, Training Loss: 0.02677697944735849, Validation Loss: 2.4650256532720616
[2025-03-25 21:35:04] Epoch 197, Training Loss: 0.026423693908035065, Validation Loss: 2.698585752362776
[2025-03-25 21:35:04] Epoch 198, Training Loss: 0.0270573053379264, Validation Loss: 2.6194777286372974
[2025-03-25 21:35:04] Epoch 199, Training Loss: 0.0262063312252726, Validation Loss: 3.5916991317766773
[2025-03-25 21:35:04] Epoch 200, Training Loss: 0.026415519020744578, Validation Loss: 2.9282294229982506
[2025-03-25 21:35:04] Weight Optimization Hit
[2025-03-25 21:35:04] Epoch 201, Training Loss: 0.01189827487835589, Validation Loss: 2.8657332544027376
[2025-03-25 21:35:04] Epoch 202, Training Loss: 0.013214004909131296, Validation Loss: 2.87337032211832
[2025-03-25 21:35:04] Epoch 203, Training Loss: 0.013814702102220331, Validation Loss: 2.9743153471705424
[2025-03-25 21:35:04] Ending Training Early
[2025-03-25 21:35:04] Accuracy: 0.3306, F1 Score: 0.3346

===== Finished SmallDilationACEModel.py at 2025-03-25 21:35:05 (Duration: 1 day, 10:35:15.432266) =====

